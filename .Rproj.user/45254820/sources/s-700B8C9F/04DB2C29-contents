---
title: "Homework 3"
author: "Liam Keefe"
date: "02/03/2022"
output: 
  html_document:
    df_print: kable
    fig_width: 11
    fig_height: 8
---

**Directions:**

Please turn in **both** a knitted HTML file *and* your Rmd file on WISE.

Good luck!

# 1. Setup (1pt)

Change the author of this RMD file to be yourself and modify the below code so that you can successfully load the 'wine.rds' data file from your own computer.

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(fastDummies)
library(caret)
wine = read_rds("./Downloads/pinot.rds")
```

## 2. KNN Concepts (5pts)

Explain how the choice of K affects the quality of your prediction when using a K Nearest Neighbors algorithm.

**Answer:** (write your answer here)

The choice of K affects prediction quality in KNN because if you have too small of a value then it makes decisio-nmaking unstable due to a lack of substantial indicators to go off of. Further, if the K value is too large then it could also have the same effect. Therefor finding the substantial value of k for the KNN model is essential for its effective predictability.

## 3. Feature Engineering (3pts)

1. Create a version of the year column that is a factor (instead of numeric)
2. Create dummy variables that indicate the presence of "cherry", "chocolate" and "earth" in the description, allowing for capital letters.
3. Create 3 new features that represent the interaction between time and the cherry, chocolate and earth indicators
4. Remove the description column from the data

```{r}
wino <- wine %>%
  #Year factor variable
  mutate(year_f = as.factor(year)) %>%
  # Description dummy variables
  mutate(cherry = str_detect(description, "[Cc]herry")) %>%
  mutate(chocolate = str_detect(description, "[Cc]hocolate")) %>%
  mutate(earth = str_detect(description, "[Ee]arth")) %>%
  # Interactions
  mutate(cherrytime = cherry*year) %>%
  mutate(chocolatetime = chocolate*year) %>%
  mutate(earthtime = earth*year) %>%
  # Removing description column
  select(-description)
```
## 4. Preprocessing (3pts)

1. Preprocess the dataframe that you created in the previous question using centering and scaling of the numeric features
2. Create dummy variables for the year factor column

```{r}
wino <- wino %>% 
  preProcess(method = c("BoxCox","center","scale")) %>% 
  predict(wino) %>%
  select(-id, -year) %>%
  dummy_cols(select_columns = "year_f", remove_most_frequent_dummy = TRUE, remove_selected_columns=TRUE)
```


## 5. Running KNN (5pts)

1. Split your data into an 80/20 training and test set
2. Use Caret to run a KNN model that uses your engineered features to predict province
  - use 5-fold cross validated subsampling 
  - allow Caret to try 15 different values for K
3. Display the confusion matrix on the test data


```{r}
set.seed(504)
wine_index <- createDataPartition(wino$province, p = 0.8, list = FALSE)
train <- wino[ wine_index, ]
test <- wino[-wine_index, ]

control <- trainControl(method = "repeatedcv", rep = 2, number = 5)

fit <- train(province ~ .,
             data = train, 
             method = "knn",
             tuneLength = 15,
             metric="Kappa",
             trControl = control)

confusionMatrix(predict(fit, test), factor(test$province))
```

## 6. Kappa (2pts)

Is this a good value of Kappa? Why or why not?

**Answer:** (write your answer here)

For this model the Kappa value of 0.34 displays that this model has a 34% greater precision than random chance and thus making this kappa value good. 

## 7. Improvement (2pts)

Looking at the confusion matrix, where do you see room for improvement in your predictions?

**Answer:** (write your answer here)

The areas of greatest improvement for my model is in reducing bias towards California wine indicators since across all other wine types the most common false prediction was "California". Further, beyond this another improvement could be made by finding a better combination of predictors to correctly identify wines from Casablanca Valley, Marlborough, and New York. These wines had more false predictions than true ones, the other wines had more true than false predictions, and a better model mix is needed to better detect these wines in the data.
